{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMfrDY6YTqdEwW3P93e8v/l"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## Step 1: Mounting Google Drive"],"metadata":{"id":"xNtBj31S9ocx"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sC1oIbvv1uKm","executionInfo":{"status":"ok","timestamp":1743323022794,"user_tz":300,"elapsed":18220,"user":{"displayName":"Samyak Shrestha (Caesar)","userId":"13083503381857072620"}},"outputId":"c9e06c33-fd87-4929-aa59-ce905bafa064"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive/llm-finetuning-project/llm-finetuning-summarizer\n","data  deployment  LICENSE  notebooks  project_plan.md  README.md  scripts\n"]}],"source":["# Mount Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# Navigate to the repo folder\n","%cd /content/drive/MyDrive/llm-finetuning-project/llm-finetuning-summarizer\n","\n","# List repo contents\n","!ls"]},{"cell_type":"markdown","source":["## Step 2: Scraping Paper Metadata (arXiv API)\n","\n","This block uses a custom Python script `arxiv_scraper.py` (stored in the `/scripts/` folder) to query arXiv for papers related to **LLM fine-tuning**.\n","\n","### What This Code Does:\n","- Imports the `search_arxiv()` function from the script.\n","- Executes a search query on arXiv using their public Atom XML API.\n","- Retrieves metadata for each paper, including:\n","  - Title\n","  - Abstract\n","  - PDF URL\n","  - Published date\n","- Prints a list of papers with direct links to their PDFs.\n","\n","This is the **first step in building our QA and RAG corpora**. Later steps will filter, download, and curate these papers for use in fine-tuning and retrieval-augmented generation (RAG)."],"metadata":{"id":"kqw8w0GeBIhK"}},{"cell_type":"code","source":["# Adding the scripts/ directory to Python’s module search path\n","import sys\n","sys.path.append('/content/drive/MyDrive/llm-finetuning-project/llm-finetuning-summarizer/scripts')\n","\n","from arxiv_scraper import search_arxiv\n","\n","papers = search_arxiv(query=\"llm fine-tuning\", max_results=10)\n","for paper in papers:\n","    # Printing each paper’s title and direct PDF URL, followed by a separator\n","    print(paper['title'], '\\n', paper['pdf_url'], '\\n---\\n')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eklaXL8R9y_1","executionInfo":{"status":"ok","timestamp":1743320107035,"user_tz":300,"elapsed":1665,"user":{"displayName":"Samyak Shrestha (Caesar)","userId":"13083503381857072620"}},"outputId":"2a72acbd-d36d-4c55-c2b1-fa795a4330d6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Beyond Fine-Tuning: Effective Strategies for Mitigating Hallucinations\n","  in Large Language Models for Data Analytics \n"," http://arxiv.org/pdf/2410.20024v1 \n","---\n","\n","Beyond Fine-tuning: Unleashing the Potential of Continuous Pretraining\n","  for Clinical LLMs \n"," http://arxiv.org/pdf/2409.14988v1 \n","---\n","\n","Revisiting Zeroth-Order Optimization for Memory-Efficient LLM\n","  Fine-Tuning: A Benchmark \n"," http://arxiv.org/pdf/2402.11592v3 \n","---\n","\n","Balancing Continuous Pre-Training and Instruction Fine-Tuning:\n","  Optimizing Instruction-Following in LLMs \n"," http://arxiv.org/pdf/2410.10739v1 \n","---\n","\n","AMOR: A Recipe for Building Adaptable Modular Knowledge Agents Through\n","  Process Feedback \n"," http://arxiv.org/pdf/2402.01469v2 \n","---\n","\n","CURLoRA: Stable LLM Continual Fine-Tuning and Catastrophic Forgetting\n","  Mitigation \n"," http://arxiv.org/pdf/2408.14572v1 \n","---\n","\n","Keeping LLMs Aligned After Fine-tuning: The Crucial Role of Prompt\n","  Templates \n"," http://arxiv.org/pdf/2402.18540v2 \n","---\n","\n","Preference-Oriented Supervised Fine-Tuning: Favoring Target Model Over\n","  Aligned Large Language Models \n"," http://arxiv.org/pdf/2412.12865v1 \n","---\n","\n","Targeted Efficient Fine-tuning: Optimizing Parameter Updates with\n","  Data-Driven Sample Selection \n"," http://arxiv.org/pdf/2403.08484v2 \n","---\n","\n","DELIFT: Data Efficient Language model Instruction Fine Tuning \n"," http://arxiv.org/pdf/2411.04425v3 \n","---\n","\n"]}]}]}